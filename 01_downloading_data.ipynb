{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfe228d-e9e1-4516-bbb0-958a1cce37f0",
   "metadata": {},
   "source": [
    "# Time Series & Sanctions: An Econometric Fever Dream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867553e-dcdc-47ae-8e69-63b527c74925",
   "metadata": {},
   "source": [
    "This is a very simple notebook (_some_ say the best notebook) to practice downloading and manipulating Yahoo Finance data in Python. The focus is on the python code and the data, not on accuracy of the financial analysis. But let me tell you something folks, I made a huge discovery: pandas is ripping me off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f0430-f2c8-4d61-91c0-261a44beda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af38b7fd-6a6c-4a83-b45c-2324f89bb539",
   "metadata": {},
   "source": [
    "I import so much from pandas. So much! And what do they import from me? Nothing. Zero. Not even a thank you. Total disrespect!\n",
    "\n",
    "This ends now.\n",
    "We’re imposing tariffs. We’re bringing back fair trade one import at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e1e1a-c3ea-45c2-8956-abb59bb33cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a very smart import. Probably the smartest. Some people call it genius.\n",
    "import tariff\n",
    "\n",
    "trade_imbalance = 0\n",
    "if (trade_imbalance > 0):\n",
    "    base_tariff = trade_imbalance / 2\n",
    "    print(f\"Imposing a {base_tariff}% base tariff!\")\n",
    "    tariff.set({\n",
    "        \"numpy\": base_tariff,     # numpy thinks it's smart. Not smarter than me.\n",
    "        \"pandas\": base_tariff + 10,   # pandas? Total disaster. Imports way more than it exports. SAD!\n",
    "        \"matplotlib.pyplot\": base_tariff  # We love charts. But not without consequences.\n",
    "    })\n",
    "else:\n",
    "    tariff.set({})\n",
    "    print(\"Smart move, very smart — just giving them a little break!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ea94a-5cbd-4bc0-af35-d6dccdcdcc8d",
   "metadata": {},
   "source": [
    "## Downloading and Exploring Data\n",
    "\n",
    "Import [S&P500](https://finance.yahoo.com/quote/%5EGSPC) data from Yahoo Finance. The ticker is \"^GSPC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404fb16-7ab5-4d0b-8ab5-54705b489e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500 = yf.download(\"^GSPC\", start=\"1900-01-01\", multi_level_index=False, auto_adjust=True)\n",
    "df_sp500.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c8274-2742-4121-a141-36b693040712",
   "metadata": {},
   "source": [
    "Preliminary data exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7e27d-cf13-41b7-8e7b-4caa0833ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf9216-0ded-4b80-8c9f-1beff772b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5809b-30a5-469d-8909-778cc6ec31cd",
   "metadata": {},
   "source": [
    "The _Open_ column presents some zero values, which is unusual for financial data and probably denotes missing data. Let's investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ce197-c036-4376-92d4-430069e4a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros= sum(df_sp500[\"Open\"] == 0)\n",
    "print(f\"There are {zeros} zeros in this column:\")\n",
    "df_sp500[\"Open\"].plot()\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"S&P 500 Open\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2dc3ed-e680-4dcf-b15d-9e8768782bc7",
   "metadata": {},
   "source": [
    "Notice that the historical record of opening values is incomplete, but it becomes more reliable starting in the early 1980s, thanks to advancements in trading technology. Much of the pre-1980s data was reconstructed from newspapers, end-of-day reports, or monthly summaries, which often included only high, low, close, and volume. More accurate historical data exists, but it is not available for free in yahoo finance. Missing data is filled with **zero**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8ce66-9afc-48db-bb37-cdb6dbaa4916",
   "metadata": {},
   "source": [
    "Let's plot close prices, which we expect to be more reliable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f2282-3f7d-434d-a788-b7b5dc1ab4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500[\"Close\"].plot()\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"S&P 500 Close\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5f098-a0e7-441b-8526-aa88f312733c",
   "metadata": {},
   "source": [
    "To create more complex representations, like candlestick graphs, we can shorten our time series considering only post-1985 data (when open values where recorded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022ef6d-9aef-4ddf-86d4-b5c14cf251df",
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick = df_sp500[df_sp500.index > \"2000-01-01\"]\n",
    "candlestick.reset_index(inplace=True)\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=candlestick[\"Date\"],\n",
    "                open=candlestick['Open'],\n",
    "                high=candlestick['High'],\n",
    "                low=candlestick['Low'],\n",
    "                close=candlestick['Close'])])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(text='S&P 500 Candlestick Graph with Rangeslider'),\n",
    "    yaxis=dict(\n",
    "      title=dict(\n",
    "        text='S&P500 Index'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958120b2-ca73-41fc-9f41-5a289449513d",
   "metadata": {},
   "source": [
    "## Market Recovery Times \n",
    "\n",
    "We want to evaluate market recovery times. We start by creating some utility columns. In _Previous Max Close_ we store cumulative max values from the _Close_ column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cf52a-017d-4da0-969c-e4fb506d7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500[\"Previous Max Close\"] = df_sp500[\"Close\"].cummax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2daf04-7385-4af7-976d-f8606cb0162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp500.loc[:, [\"Close\", \"Previous Max Close\"]].plot()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca1c82c-24ad-402d-8619-7b1eeae0c2af",
   "metadata": {},
   "source": [
    "The cummax method is useful, but we'd like to keep track of the date where the previous max occurred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea91e5a-f96a-464a-a400-698910858583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask specifying where a new max occurs\n",
    "is_new_max = df_sp500[\"Close\"] == df_sp500[\"Previous Max Close\"]\n",
    "# Find the corresponding dates. This creates a DateTimeIndex with NaT where is_new_max is False\n",
    "new_max_dates = df_sp500.index.where(is_new_max)\n",
    "# Forward-fill the last max date\n",
    "last_max_dates = pd.Series(new_max_dates).ffill()\n",
    "# Align index\n",
    "last_max_dates.index = df_sp500.index\n",
    "\n",
    "df_sp500[\"Previous Max Close Date\"] = last_max_dates\n",
    "df_sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c940a91-f1b7-4db9-843b-1bf3aeeca987",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_days = df_sp500[\"Previous Max Close Date\"].value_counts()\n",
    "\n",
    "# Values counts are already sorted\n",
    "recovery_days = recovery_days[recovery_days.iloc[:] > 90]\n",
    "recovery_days = recovery_days.reset_index()\n",
    "recovery_days.columns = [\"Crash Date\", \"Length (trading days)\"]\n",
    "recovery_days[\"Length (years)\"] = (recovery_days[\"Length (trading days)\"] / 251).map(lambda x : round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c20eda-51cb-4d9b-ace1-7f5f6089bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_days.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0359e7b-05dd-401b-b44d-08a6fcc5ae26",
   "metadata": {},
   "source": [
    "This is a very rudimental indication of market crashes, definied as periods between local max values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0a5e0-74e6-4ca6-b962-7c1d3317f5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
